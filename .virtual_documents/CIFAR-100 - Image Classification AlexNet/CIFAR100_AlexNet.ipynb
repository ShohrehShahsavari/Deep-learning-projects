import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow.keras as keras
import warnings
warnings.filterwarnings('ignore')
from keras.datasets import cifar100
import cv2


# ## Run following code in crm terminal
# C:\Users\ebsor\anaconda3\python.exe -m pip uninstall -y numpy pandas scipy scikit-learn numba shap tensorflow torch
# C:\Users\ebsor\anaconda3\python.exe -m pip install --no-cache-dir ^
# numpy==1.24.4 ^
# pandas==2.0.3 ^
# scipy==1.11.1 ^
# scikit-learn==1.3.2 ^
# numba==0.57.1 ^
# torch ^
# shap

# C:\Users\ebsor\anaconda3\python.exe -m pip install tensorflow==2.10.0 protobuf==3.19.6
# C:\Users\ebsor\anaconda3\python.exe -m pip install --no-cache-dir opencv-python==4.8.1.78





(X_train, y_train), (X_test, y_test) = cifar100.load_data(label_mode='coarse')


X_train.shape


X_train = X_train.astype(np.float32) / 255.0
X_test = X_test.astype(np.float32) / 255.0


### it needs more than 28 GiB so it doesnot work
# X_train = np.array([cv2.resize(img, (224, 224)) for img in X_train])
# # X_test = np.array([cv2.resize(img, (224, 224)) for img in X_test])

### but it does work
X_train = np.array([cv2.resize(img, (140, 140)) for img in X_train])
X_test = np.array([cv2.resize(img, (140, 140)) for img in X_test])


### Anoder way
# def preprocess(img, label):
#     img = tf.image.resize(img, (224, 224))
#     img = tf.cast(img, tf.float32) / 255.0
#     return img, label

# train_ds = tf.data.Dataset.from_tensor_slices((X_train, y_train))
# train_ds = train_ds.map(preprocess).batch(32).prefetch(tf.data.AUTOTUNE)



# from tensorflow.keras.preprocessing.image import ImageDataGenerator

# # This will resize on the fly during training
# datagen = ImageDataGenerator(
#     preprocessing_function=lambda x: tf.image.resize(x, (224, 224))
# )


# # Pre-allocate the array with the target shape
# X_train_resized = np.zeros((50000, 224, 224, 3), dtype=np.float32)
# X_test_resized = np.zeros((10000, 224, 224, 3), dtype=np.float32)

# # Fill it incrementally
# for i in range(len(X_train)):
#     X_train_resized[i] = cv2.resize(X_train[i], (224, 224))

# for i in range(len(X_test)):
#     X_test_resized[i] = cv2.resize(X_test[i], (224, 224))


X_train.shape


input_layer = keras.layers.Input(shape=(140, 140, 3))

C1_layer = keras.layers.Conv3D(filters=96, kernel_size=11, stides=4, padding='SAME', activation='relu')(input_layer)
pool1_layer = keras.layers.MaxPooling3D()(C1_layer)
